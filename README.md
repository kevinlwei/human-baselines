# Position: Human Baselines in Model Evaluations Need Rigor and Transparency

**Authors:** Kevin L. Wei (Harvard), Patricia Paskov, Sunishchal Dev (Algoverse), Michael J. Byun, Anka Reuel (Stanford/Harvard), Xavier Roberts-Gaal (Harvard), Rachel Calcott (Harvard), Evie Coxon (Max Planck School of Cognition), Chinmay Deshpande (CDT) | **Contact:** hi@kevinlwei.com

[Link to full paper, including checklist, on OpenReview](https://openreview.net/forum?id=VbG9sIsn4F)

Code and data forthcoming.

## Position Statement

Human baselines in foundation model evaluations must be more rigorous and more transparent to enable meaningful comparisons of human vs. AI performance.

## Our Research Contribution

We:
1. Conducted a **systematic review of 113 human baselines**
2. Performed a **meta-review of measurement theory literature** from across the social sciences
3. Developed a **framework of key considerations** for creating or assessing human baselines with rigor and transparency
4. Provide a detailed **checklist** to put our framework into practice

## Key Framework Components

Our framework for rigorous human baselining consists of five essential stages:

1. **Design** - Selecting appropriate test sets, using iterative processes, collecting adequately sized samples, satisfying ethics review requirements

2. **Recruitment** - Specifying human populations of interest, developing sampling/recruitment strategies, employing quality controls for baseliner recruitment

3. **Implementation** - Employing quality controls in baseline implementation, controlling for method effects, controlling for level of effort, collecting explanations from baseliners

4. **Analysis** - Quantifying uncertainty in human vs. AI performance differences, using consistent evaluation metrics, scoring methods, and rubrics

5. **Documentation** - Reporting key details about baselining methodology and baseliners, adopting best practices for open science and reproducibility



## Key Takeaways

1. **For researchers creating baselines:** Adopt cost-effective improvements like power analyses, careful test set selection, and transparent reporting of baseline methods

2. **For the research community:** Establish more stringent norms for scientific rigor in AI evaluations, as seen in other fields balancing cost and methodological quality

3. **For funders:** Allocate resources for developing and maintaining high-quality human baselines, recognizing their value for the field

4. **For all stakeholders:** Use our framework as a reference for designing, implementing, and assessing human baselines (not as rigid requirements)


For more discussion, please see the full paper.